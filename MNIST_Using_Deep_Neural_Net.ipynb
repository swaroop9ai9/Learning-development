{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3194,
     "status": "ok",
     "timestamp": 1579416126169,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "l9C4aAIGOIUH",
    "outputId": "a7e469c6-173a-4ec8-f5fc-8b41c1213bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3105,
     "status": "ok",
     "timestamp": 1579416126172,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "tmOnjVEYWhJi",
    "outputId": "01c85b4b-ebe1-45ee-fb22-559d2eb4eb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainX : (60000, 28, 28)\n",
      "Shape of trainY: (60000,)\n",
      "Shape of testX : (10000, 28, 28)\n",
      "Shape of testY: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of trainX : {}\\nShape of trainY: {}'.format(trainX.shape, trainY.shape))\n",
    "print('Shape of testX : {}\\nShape of testY: {}'.format(testX.shape, testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3074,
     "status": "ok",
     "timestamp": 1579416126172,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "oYxVFm1sLUcB",
    "outputId": "9a552e8e-8c7f-4d62-c0c9-5f7912aaea1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of trainX : uint8\n",
      "dtype of trainY: uint8\n",
      "dtype of testX : uint8\n",
      "dtype of testY: uint8\n"
     ]
    }
   ],
   "source": [
    "print('dtype of trainX : {}\\ndtype of trainY: {}'.format(trainX.dtype, trainY.dtype))\n",
    "print('dtype of testX : {}\\ndtype of testY: {}'.format(testX.dtype, testY.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3047,
     "status": "ok",
     "timestamp": 1579416126173,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "ZzdZKBbYW6uI",
    "outputId": "372f7082-7a3a-4c93-8534-d1c740f1f7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3027,
     "status": "ok",
     "timestamp": 1579416126174,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "UbiHj5YPOIUc",
    "outputId": "a34c2d52-a7ba-49e5-a4af-3d0858a36251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3003,
     "status": "ok",
     "timestamp": 1579416126174,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "eq6KYMbnOtDj",
    "outputId": "0d312277-8ed9-4e0c-d8eb-2486a07c61a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdKNg_okjuWe"
   },
   "outputs": [],
   "source": [
    "trainlabelsY = trainY\n",
    "testlabelsY = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2960,
     "status": "ok",
     "timestamp": 1579416126176,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "RHV3b9mzOIUq",
    "outputId": "ee035238-05ae-4297-9b88-524657c9c46a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainY: (60000, 10)\n",
      "dtype of trainY: float32\n",
      "First 5 examples in trainY now are: \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape of trainY:', trainY.shape)\n",
    "print('dtype of trainY:', trainY.dtype)\n",
    "print('First 5 examples in trainY now are: \\n', trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2940,
     "status": "ok",
     "timestamp": 1579416126177,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "RNNXoui8aQ3w",
    "outputId": "7ed8e7ba-b35d-4443-d480-a20a578b7cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testY: (10000, 10)\n",
      "dtype of testY: float32\n",
      "First 5 examples in testY now are:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape of testY:', testY.shape)\n",
    "print('dtype of testY:', testY.dtype)\n",
    "print('First 5 examples in testY now are:\\n', testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3725,
     "status": "ok",
     "timestamp": 1579416126991,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "3AsLFYvDpnjC",
    "outputId": "b645911d-6552-4a5b-883d-889f7f9f0384"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAABICAYAAADF252hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO19eZxU1ZX/99VeXdUrvdHd2s0qIiBq\nuyEYxaAYQ4KCBpvEzPARnejEDRJMzDgkxMQx+UWN48cE40ZcmMmAMUHBiQSjIwq4BQxREGVpeoHq\ntbprr3q/Px7n9H2vq7urqruqusL9fj796dree+fdd+49+7mKqqqQkJCQkJCQyB5M2SZAQkJCQkLi\nZIcUxhISEhISElmGFMYSEhISEhJZhhTGEhISEhISWYYUxhISEhISElmGFMYSEhISEhJZxrCEsaIo\n8xVF+URRlE8VRbl7pIhKN3KR7lykGchNuiXNmUMu0i1pzhxyle6UoKpqSn8AzAAOABgPwAbgrwCm\npnq+TP3lIt25SHOu0i1plnRLmkfHX67SnerfcCzj8wB8qqrqZ6qqhgCsB/DVYZwvU8hFunORZiA3\n6ZY0Zw65SLekOXPIVbpTgnJCA0n+QEVZDGC+qqo3nnj/DQDnq6r6r4McM1rbfQVUVXXG+yJVmh0O\nB0499VS0t7cDAHw+n6jxwel0ori4GIFAAADQ2tqKaDQ6IjSnQrfFYgEAjBkzBm1tbYhEIgP+1ul0\nwuFwAAA6OzuRJA+NyFjbbDbk5+cDAIqKihCJRNDW1gZAG2uHw4Hi4mIAQEFBAWKxGH/v8XiSoXdQ\nmpOlO1lYrVaEw+GUjlVVVRnou1T5Iz8/H2VlZcwfgUAAqqrCbDYDANxuN3p6enD06FGiIVmyR3wu\nZgBp4w+3241gMAgA/fjAZrPB5XKho6Mj1dN7VFUti/fFyTjW6cRgc5FgSTcRiqLcBOCmdF9nmPCK\nbwajWVGUfgvMzJkzAQBLlizBokWLAADRaBQulwtOp8Y3Y8aM6Xeuffv2IRaLAQBOO+00tLa24tVX\nXwUA/PznP8dHH32UMM1D0T0Y3G43lixZAgC4/fbbEQqFWGCFQiGEQiEWfHa7HTU1NXjppZcAAG+/\n/TZ+97vfJXO5hMfaiCuvvBJ33nknAMDv98NmswHQBEJ+fj6mTZsGAKioqMDBgwdZYDQ3N6Orqwt2\nux0AUF1dja1bt+K2225LieZk6RaxdetWVhLa2tqwfPlyHDx4UPebqqoqAMC2bdvgdDpx6NAhAMD8\n+fPR29ub7CUTotnI16Wlpbj99tsBAF/84hd57Hp7e2G32zFlyhQAYL4gQdHY2Ijm5mbm+/b2drzx\nxht45JFHACARwZEyf2QRKfOHyWTiNQAAampqsGzZMgDAihUrUFBQMOjx0WiU+XzVqlV4+OGH+51f\nNAIMOJQKzVnGiM3F0YbhCOOjAE4R3tec+EwHVVXXAlgLjF6tBUBIfJOLNAO5SXcu0gzkDN065AjN\nkj+yhByh+R9irONhOG5qC4B9AC6DJoR3AWhQVfVvgxwzWgfqb6qqTov3xWA0FxQUYN26dZgxYwYA\nTQv1ejXFLRAIIBwOs+vZarWisLCQLZtYLNZPW3U4HGxR2Gw2vPnmmwCAb3zjG0nRPBTd8XDttdcC\n0CzOe+65h62ziooK2O12tmh6enrwpz/9CS+88AIAzar+/e9/n8ylUhrrCRMmYPXq1WhtbQUA5OXl\nwWTSUh5isRgikQhOOaVPN4zFYmxxdHV1IRKJsPXW3t6O6upqdHZ2AgBWrlyZMs1D0W3E66+/jgkT\nJgDQvAxOp5N5ZsOGDfj617/OLt9AIIDOzk74/X4AwJlnnpnoZQAk56YWLeMJEybgj3/8I4818TKg\nWWLBYJDDL263mz8DNL4tKytjt7bNZoPNZoPP5wMA/OpXv8KLL744GNkp8UeWkTR/iLwLAO+//z4A\nYNKkSRwC8vl86O3t5fcdHR3o7OzE2LFjAWhzwOfz8ZrhdrvR3t6O1157DQCwdOnSoeh+T1XV+kRp\nTgaKorEeWf7iWkffAfHDGLNmzQIAbN++PV6YZkTXvUHOMyB98fDb3/4WDz74IADtWdrtdp4TJ86T\nPje1qqoRRVH+FcCr0LLenhxMEI8EjANELrLZs2dj8+bNut+ZzeZB454GBFKhZ+PGjaitrcWxY8cA\naBOLFqFIJAJFUfi9oijweDy80AJ9E5Lg9/s5hqyqKi6++GIAwJQpU/Dxxx+PCM0DgVy+nZ2d+M//\n/E924QaDQdjtdhZc7733Hp566imMGzcOAHD8+PFkL5US3StWrNBdy2Qy8SIViUQQiUTw+eefA9CE\nr8Ph4IWOXKykGFksFhw6dIjd2ldddRVefvnlEac5Htra2njs2traUFJSgsrKSgDAt7/9bZx55pms\n3HV0dMBisXCsO50QF52f/vSnaGlpYYFrtVr5e+Jrt9sNQOOPQCDAY+xyuRAOh3UxZZPJxPx16623\n4k9/+hMATbGLgxHl6wwhKZoVRdG5pt9++21Mnz4dANDS0sJjqaoqbDYb821lZSWqqqpYsQmFQnA6\nnays+f1+WK1WNDQ0ANCexcKFC4d5a8OHUaDFE3CXXHIJAGD69OmYNGkSAOAnP/kJduzYgbvvvls8\nZsT4wxiaEd+rqgpFUfrJHKvVCkALy0ybNg0bNmwAAEyePJnl0cKFC1PJlRhezFhV1VcAvDKccyQD\nEl7RaBQTJ07EjTfeCEBjwt7eXhZkO3fu1AliRVH4WEVRdN+ZzeZkE6dwzjnnAABqa2vh8XhY4JrN\nZhYQ1dXVOustHA7DYrHwtRRFgdVqZVq8Xi8aGxt1tNFvb7zxxkSst2GBFsbS0lIcOnQId911FwAt\nhlVWVsaCrq2tDaWlpTolIxN4+umnceedd7JAbm1t7RevDIVCfA8A0N3dDQC8WBFCoRAKCwtx5MgR\nABhKEI8oPvvsM1xwwQUANMEWDAZ1Y3jw4EHMmTMHAHD06FE4nU7k5eVlhDayuCorK9HV1cUCNBKJ\nMA0ul0sX54xGo4hGo8z3LpdLF8eMRqPo6enhuelyubBgwQIAYO/KyQZxob766qtx/vnno7GxEUDf\nugD0ec/o916vt99aFo1G2TImD9Hhw4cBAJdffjmuvPJKANAZK+mAUWjRf+PaesMNN+Cdd95hHr/t\nttvQ1NTECuj+/fvZS3DHHXfgww8/TBvNJHDF90ZjidY5v98Pk8nEa83FF1+MjRs38vuPP/4Yt956\nKx+bStKl7MAlISEhISGRZaQ9m3okQVpLNBrF3Llz8cUvfhGAlsFpt9tZe583bx5+85vfcMxLVVWd\nhuZ2u1mzJ5dPMrj00ksBaO5Pu93O5zKbzRwnWLVqFZqamljjraqqQnNzM2u1oVAIdrud3X1nn302\nvv3tb3MWs8Vi4fMuXrw47ZaxaJGTZQloZUAtLS08ttXV1YhGo/004HRj586dePvtt/GVr3wFALBj\nxw7WWvPy8tDW1saWscfjQSAQYJotFgu6u7tRVtZXxZGXl4e77858Q5+9e/fqtO/e3l6mm6wDsuQp\nzEEWfrpBWd6VlZWIRqNsGbtcLuYP4neyKOg/3RO5YOnzaDSKsrIy5mubzYZ58+YBODktY6MnbuPG\njfB4POzl6ezsZKvKYrHorDXKjBYhrm1k6ZFl3dXVhVde0RyXY8eORUtLiy6MlilMmTKFr3vJJZeg\nvr6eee3pp5/GG2+8wdbwOeecg3PPPReAtkZOnDgRn376adpoM46n+Gyi0ajOwo3FYpyX8vLLL6On\np4efzV133cXlfPEqbhJBTgljWrQA4Nxzz0VdXR0AjcFNJhOXBZ111ll44IEH8O677wIA9uzZg7//\n/e8AgPPOOw/nnnsutm/fDkCL13R1dSVFx+LFiwFoDC1OLofDwed6/PHHcfnll+Pss88GADz11FO4\n+eabuVyppKQEZrOZFYYHH3wQt9xyCzOtw+FgRWHKlCmYPHky9u3blxSdyYCUBJrcxGRFRUX9fisy\nG9GbCfzyl7/kcpvDhw+zy7q3txc+n48ToQCNJyhZzmKxwGq18veFhYXYvHlzxoSciKNHj/IEN5lM\nsFqtaG5uBqAlfni9Xp7UZrMZiqIkzZ+pgpQBs9mMyspK5gmTycRu5qamJhw4cIDLsSg8RGMdDodh\ns9n4XF/+8pcRCASYj9xuN1wuV0buZzSC1goqDezs7ERPTw9qa2v5PSnhJDCNuSVGiIqxOHd7e3tZ\nsbvkkkuwfv36pENyicIofEgRnjVrFlpaWniuPfHEE7jzzjvR1NQEQFv3ysvL+fhPPvmEw4Dz5s1D\nIBBIqzA2JtIRKioqUFxczCWp9fX1qKio4PWuo6MDLS0tKCwsBKDl0gwXOSOMRQEwb9481NfX8+Lq\ncrkwefJkTJ48GQCwa9cufPrpp2x1XnjhhbjmmmsAaIvFrl27ON4cDAaxbdu2pGihrNYjR47AZDJx\nwgUAXV3gli1beJGaOnUqVq5cyZmkCxYsgMVi0WmEkUiEF6poNMoMcvjwYVx44YVpFcY0Vna7HYFA\ngCd0LBZjoUAwmUzMxBQrTDcsFgsikQhmz54NALjvvvv4O5/Ph0gkwrEzv98Pi8XCEycYDOoWNJPJ\nhD/+8Y8ZoduIpqYmFsZkRZKg27t3L6xWK9NKtdGZisuvX78eAPDmm29i6dKlnOD2k5/8pF8CIS22\nTqcTTqeT+dbhcKC3t5et3u9973vYtWsXKioqAGjPavz48Rm5n9GMCy+8kF/bbDadJ4FgrA8eiA+M\nSUdiBQfNz/r6eqxfvz5tnixxvVBVldeTQCCAadOmcYLWzTffjPnz57PhBIATYAGgvLycEwerq6ux\nbNkyvPXWWwAwVN+FYdM9YcIEPPTQQwA0I8Tr9eKMM84AoCnRZ5xxBl5//XV+b7PZ2BM6EkaJjBlL\nSEhISEhkGaPaMh5IE1yzZg1nfgKalh6JRNiNPXv2bNTX1+tq+MjVEYlEcOutt7J2Ti7nRDFt2jR2\nj5Kbmuh0Op26MpRp06ax5jR27Fjcd999/NtwOAxFUXQaclNTE6qrqwHoLWO/3485c+bgmWeeSYrW\nZCBmRxszNuNlo9N7Mf6ZTojdtADgwIEDXCIUCATg9Xp5vKichjLEqX0j0UwdrbIBj8fD4ZWPP/4Y\ngUCAeYKeAfExWTmptsNMFg888AAAzUrYtm0bPvjgAwCat4csY0VR0N3dzXxOMU6yuBRFQWFhIVsU\nBw4cwNKlS/lZtLW16eov04mBMmXJehsofmrsiiWCKiCGa2GS+1gsXSKa6XlTjS3RSW5oMXxgzIex\nWq26mm/yzC1dujSteSc0XjQudH8mkwlz587Fs88+CwD4l3/5l0HPM2bMGPYuvvvuu1xaSd+NdJmf\nOLcOHDiAf/qnfwKAAa9Da7/D4cCePXvw3//93wC0tXsgb2Ki8flRLYwHYviOjg6MHTuWH7jdbofF\nYtG5RpxOJzPInDlzuJDcZDKhvLwcW7ZsSYmmVatWsTu0p6dHV1oQCAR44Ovr6zFmzBiUlJQA0CZJ\nRUUFP/xAIACbzcaxtK997WsoLi7meyosLNRN2Pr6uLX5Iwaa4D6fj2PwAHRuL6DvmWRqQR0IJpOJ\nk15isRjsdjvHpWw2GwKBgC7HQJwQolss02hpaeHXFDMWXeiqqupqGS0Wy3B6DycFch1edtllWLRo\nES6//HIAwDPPPINvfetbADT33cSJE3mukZCjZK9QKIRYLMaLr9frxapVq/hZdHR0cMho1qxZ7JJM\nB4zrh7H8xrhI0j3+4Ac/YKXYiJFQjM4880xd+Z3D4eDxcTgcHLYgpYDWMVIixPciqPSG7rO4uJjP\nm+6ELeNYUwjxjTfewBtvvMGfO51O7mdOEEOQY8eOZZ7wer3YvHkzNyCqra1Ne809nd9kMsFsNvd7\n3hTSvOaaa9DR0YEvfOELAID/+I//6Jf8RUjUYJFuagkJCQkJiSxjVFvGA4GaaYjWXFdXF2s1dXV1\nuoJuk8nECSfk/hVbJyaD7du3c8ekiRMnoqCggJNX9u/fzxrRO++8o9NqKctRdAeLLiev14t9+/Yx\nnaJ12tTUlGzLyaQhWmdms1lXrmXM5rRYLGwZl5eXp5UuI41EV2Njo64NaTAY1HXJERtRUGczskYo\nWzkbZR4AjG3ydK9jsRjzUDQaZbdwJnD//fcD0Ky/pqYmrkBYsGAB7r33Xv5dOBzme6AyNxpDs9kM\nq9XKlnNHRwd27tzJHoFt27Zh//79AJBWq1gEWV7G53z99dcD0Kovrr32WvZEeTwevPDCC/y9CJvN\nhu9+97v48Y9/nDI9FouFrSVVVblRCtFKnhEKDxlbSw7ktTKZTBw6AzS+pu9rampSpnc4oLXEmEA5\nUFZ3WVkZhzSokyLxUibmqeg9Ea1iSiBdt24dAK19sMlkwsSJEwFA1wkN0BJ2H330UQDgjT+GwqgW\nxiITRqNRfihVVVUIBoO8INjtdoRCIS4FKioqQltbGws2m82mK2vZvXs3n6u+vp5LoBLBY489hsce\newyA5gaaNGkSu7e+8IUv8ALz0UcfobOzkydWPFeFGIsNBAJMG5BQX9kRQ3Fxsa5OVFXVAcspqOWn\n2FFJdK1lCgcPHmQabTYbiouLudwmEolgzJgx7N6lTlf0+0wLXyOM7kUx3irGOelZDGenpmSwceNG\nAJqbur6+nrs2/eEPf2Cl6/DhwyxwAc2tKmaSRiIR+Hw+do8WFBSgtrYWd9xxBwDN1UiZtR988EHa\nOiwZWxsC4IXz2muvxaxZs9gNf+DAATQ2NrLSU1dXhy996Utxz7tkyRKcf/75w6Lt7LPP5vGjuUbj\n5ff7eW2iz4h+o3ua5qzxP/G52Pe8p6cH559/Pnbs2DEs2pOFqFgC2v2Ja6GxJtflcuGb3/wmAGDT\npk14/vnnWTin0hMiWQwUGqUx37RpEwBNkSwsLOSyw7lz53JPCZpHVEtNnw+FUS2MaWColvdrX/sa\nAK0pwfHjx3Vt4FwuF1u71FBDLJ4XtzJ89NFHedvD4aSkk9ZPSsHcuXOZZtprVAzqA30KBpW1UHJC\nKBSCw+Hg+udMQlRsBuojKypGQN/E7+rqyrggBrRJLQo1SpoAwH2pSRiXlpZyfBno6y+bLRgVHWPj\nDGPNd6a8D1OnTgWgjW1LSwveeecdAMBFF13EZU7GloEUxxT5WvSstLS04Pnnn2eh+9lnn3Eb0uGW\n6omeEpvNpssREPm4qKgI9913H68fPp8Pzc3N2LlzJwCNH5xOJyep1dTUYM2aNXx8eXk5H/uLX/wC\nU6ZM4VrYVOpLRSU8Fov1i0uKiT92u13XU91oZYr3arfb0dXVxZ46sT+/3W7HHXfcEdfaTxXJbqZA\nEGuh6T3B4/Fw4mB9fT1+/etf88Yq6V4b4/WqHugeGxsbkZ+fzzlBmzZt4t8cO3YM4XCYy6ASzTOQ\nMWMJCQkJCYksY1RbxsZSDyr6DgaDsFqtuvaY5eXlbKG1tbXpCt5dLhdbSY2NjWhoaMDPfvYzAGDt\nPxmQtmS1WhEKhVgj6u7u1tE0UMZgPNBxtDuS+Fm87RZHEkZrJ5Hfi41OMgXREo5EIlxmEAqFdBnH\nHR0dvKMNoGmqYiwq2zC6okWvA+2KBPTFqagUKt2gcj+LxYKamhqO81JTFUDLbSA6gfgbrdDOTYAW\nA/T5fOyZqKmp4QqCyspKfPbZZynRanTpi1Yx0JcRDgANDQ1oa2vD3r17AWi8U1BQwN2V/H4/fD4f\nVyy0tLSgoaEB3/nOd/j7PXv2ANAsTIfDoev2lizEY8lFLTaCES1f4/t4MLbPpLnZ1dXFxwaDwRFv\n0DOcNcnIM+Sp/Otf/8rNZ7785S/jiiuu4Ex98qikC/HuZ6AStzPPPBO7d+/mTO8lS5ZwSdYPf/hD\nuFwu3p0sUWRNGJM7S0xGCIfD/RZcEdRnldq80UNSVRXHjx/XuSlF14B4XrPZjBkzZgyrxSA9NLrG\ngQMHAGjC2KhAiG7eeN106HfkOhWTdcRdqtIJo9vROPnjfSbSNlhd5khCvE5+fj7HZHw+H7uLAM3V\nlZeXx63qxLpdANx6MFuxY2M3M6NwJpCgy5QwFvMXotEoC428vDzd/BFrKCmRkt4Tr9DcNJvN3Jca\n0NrA0hypqqpKWRgb62sBbQcgqmOtqKjgWN2ePXsQjUa5CxjRSfOR+IqUO1pUyS169dVX83E/+MEP\ncMstt/DOSF//+teTbtf4/e9/n9cOckUT/3o8nqQ6rpnNZuZvCnvRWuL1enVd6RYuXJiya3kkYVTg\nVq1axff/2GOP8f7tbW1teOWVV3i+GhWudILWa+JVMq5o/ILBILq7u+M+q3vuuQdmsxm/+93vkrpm\nxoWxaDkOtRjSfr6LFi3CRRddxAH8trY22Gw23UBRfSzQp70Sw4mBf5vNhp6eHq51HE5bREosoyw6\nilUD2iSzWCw65jdaQaqqcqw2Ly+v3/aOmYI4VsaWelRvJ8KYHEN1vemGKPCPHz/OnpIjR44gLy+P\naaioqEAoFOKELkqOo4YhpM1mA5MnT2ZBJe5/DfQJZjH+GolEdBt3pBOiYhyLxTgZUazZN25WQC0b\nxWY2VPdPv29paeFnI8YLxTh+oqBe7/PmzcNpp53G1l5VVRXcbjd7lo4ePcrKmMPh6LceWK1WXQtK\ncWMWyr4/77zzAGjVDJRU1djYiP3793Ny6PLly7Fq1aqk7mH8+PG65FO73c6NaJxOZ9ICU1Ts3W63\nrkkIjbXFYsHBgwezKoQJooK5evVqmM1mVoQWL17M2fYWiwVVVVUj1vTGmJ0O9E+KM8LYzGTXrl0A\ntKqAK664QvdbUQE9dOiQTglNBDJmLCEhISEhkWVk3DI2upbIPVFVVYVJkyax1XLNNdfwxg9UlkIW\n7pgxY9DU1MTats1mQ3l5Obsx8vLysH37dtZmL774YtZwurq6EA6HeYP34cBYcmDcWlB07YrZvkCf\nliaeI57VkQkYrbFEmtMbXa2Zxpw5c9jFeejQIQQCAXbxFxQU6DqYhUIhXfvUyspKlJeXcyeuTLnZ\nAeD0009n92k4HNZldsfbkCMYDLJ7ddasWRnJtqdsaNpRjFydBLKcAc16EWv+yasi8rroXhRrTJNt\npVpWVoaf//znTJOiKLowj8/n4/ETt0nt7e1FZ2cnW4yxWAwOh4N/a7fbYTab+T4dDgesVivzUyQS\n0ZXJOZ3OlKx6QNv8IC8vj62mvLw87lpGYyJ6IcReBTTWhGg0qutVEAwGUVhYqOvyRy73SCSScm8F\ngujVTOYYRVHYavT5fJgyZQrn7Ozfvx+nnHIKVqxYAUC/5s2cORPjx4/H22+/nRSdRm+kcVerZCCu\nCxs2bODcgX/+538GoN/1SdzSlTLCk0HGhTEJwTVr1qCsrIyTOWgCk5spEolwzCoUCkFRFF5ct2/f\njuuuu47rg/Pz8xEMBnWxtenTp/OEOXLkCAtyp9MJt9vNcYiRRHV1NU9as9msE8gDCTX6ntrYZarX\ns4jBrim6IIE+YS3WNmZiG0VamGhBmTp1KgvjoqIilJaWcuzO5XJh3LhxzEviTlqAVnPZ0NDAO7Rk\nShADWmKRGKs0Kj/ia+Ihykn41re+lVZhbFTCiJetVqtOaRTDKaRAiseKfcAVRYHT6eRnISYRJZtQ\n1N7eju9973sANMVk2rRpPI8ph0AMXRENZWVlKCsr0wk8McxFv6MEP9pjmu5RDMNQv2dyM7/88stJ\n3cOcOXOYPjpfKBTi85eUlLAwpSYwiSro1GtBzKugexR3YksVxh7aidBE6zqtv9XV1VixYgX+/Oc/\nA9DkwbXXXhv3WFpnkq0vHihPhzBlyhQAWjMOUgrITS4KV7F/wpo1a1BeXs5JgQRjeSWg8RfN2WSQ\ncWH8y1/+EoDWg5Q0O6AvrksalBiLBbRmHTTx7r//fvj9fm62QVby1q1bAWi1jJMmTeJsyVAoxBYI\n9W+lwR8OjA9ajPdSA3jR4hSZg6wLoos6SImWUiYtY+MG5cZ+yeJrY7ZnYWFh2rtEEaNTnGbv3r28\nmHd3d6Ouro47a02ZMgWxWIwt0BkzZqC1tZX5oaOjA9XV1dwEIp37pRpxwQUX8GJLVsNAe0ObTCbd\ngiBuKpJJUN02ED/uFi+GTBaryWSC0+nkMZ45c2a/hLpkQHkC1LyCcjTGjRuHiRMnskJeVVXF/EE0\n0z14PB709PToNrugP6Avu5ogbnFIx1MjlmTnKD17EuY0lmSU0PpEr8XkScq8NnbLI5BQp/GlPdOB\nkU9WHOq+RetUFOKrV69GU1MTb0NL9dvxEI1GUVpamlTiltjBLBaLIRKJcM348uXLdb3hx40bh69+\n9asAgNNOO42PofMEAgFW/q+77jpdIxjquCUKb0oojcVi+L//+7+EaSbImLGEhISEhESWkVHLeMyY\nMWzdHjhwAG63m+O64u5GgGYJU11ZU1MT8vLyOIb1zDPPYOHChZwJXVdXB7fbzV1xLr30Ul2LObvd\nzhY3oGlcdJ1TTjllxOrXgsGgThMV4z/kchFLnqguEICulWemIe4cJFryRGc8iJZ0JmuOqR/17t27\neaxtNpuOBmPXs1gsptNyu7u72ZoGMmsZ19XVsfvXmCNAbmkRZrOZM3crKytht9vTtmMWhYVcLpfO\n+nI6nTq+FV1zxioBugdj3SyVAtXX1zP9ybpNRQtr7NixOmu1vb0dr7/+OlvDYgauMWTkcDh0O01Z\nLBY4HA5ei8rKylBQUNBv9yxAiwd6vV4+/6FDh5La9P4vf/kLAH2+iehSp9atIt10bSoJErPAqdSM\nYDKZ+PdUpy5ebzgQ14SioiLOZRg7dix3myIYr/fDH/6Q72/GjBm6cjGilUA0WyyWpCsJRK8MgTLw\nKyoqdHxA/QcArf+6WFlD9D///PMAgC1btuhcz6LXlkDj0dvbm1I4KaPCOBKJsOCjOC+9d7vdsNls\nHN9rb2/ndH+3283lBnSeF198kYPpdXV1KCkp4YdAe6zSQxXdwRTzook4efLkERPGxtijMWYRz70n\nMjglh4jfZwJiCVY8gWCE6PIKh8MZS+Cqq6vj8iSHw8ExPlp0xLGLRCL8PEhQk8JTUVGBo0eP8kTM\nBMiFVVpaykolldsYXXqiYpItGx8AAA+BSURBVGSz2fC///u/ALSeyuecc05a4sY2m00XyxbDDrSv\nLoHK2QDohAOgPQtxL24SJlRmRpt40OtkQe5hY79up9OpO7fb7ebnbuwPLzYtET8nZaSpqQmKorCA\noD2M6f6o/zb9NhlcddVVAPqS2kKhEMrKypgnRDc0lVvRtY2hLkroovdWq1UXGxaF8Uj0KhDXhalT\np+qUW1IY48V3q6ureQtbh8PBcfN45zYqeqeeempSNLrdbixcuBAA8D//8z8IBAK6Usauri4u2fP7\n/cxHDz30UL8y15deeonbwNI5BwMZUvEEdSLIqDAWu1U1NjbC5XKx5tPZ2QmPx8OxXIvFoptMDoeD\nE7JMJhM8Hg9OP/10ANrEPHLkCFscdrsdHo9HV1hPr51OJyorK7npx8yZMznWPFwM1DNW/N4ojMU+\nxJFIhJk6kxC9BmT5DCVgxcYnmaL51FNP1WWWEt0Oh4NrRQnFxcW6BdRiseDzzz8HAEyaNAmtra1c\nh1pSUpL2HYSow5AYnzduyuFwOGCz2XSCLBKJcDzLYrHg9NNPT4swFpOwLBYLx98BvYIWr8e6mF1N\n1hr9PhqNIj8/n/tQi/W8qcSMB4Lf79ctgpnaAzpZzJ8/H4A+dpyfn8/5L88++yzztdfrRSwWY8Ft\nHFuaq7ROOhwOFBYWsvVdW1ur6+gH9FlvJPyTgag0JsODa9eu5coYUkaMEOeE+BklWyUKu92OJ554\nAoCWdNXT08PCuKenB+FwmJWImpoaXWb/Aw88gN/85jcAtP2JL730Uu6ilcg+ylSxkWr+jIwZS0hI\nSEhIZBkZtYz9fj9vL7Vs2TI0NTVxeUogEIDb7WaXktPp1HU0CQaDujgl7bxC70XLiM4luq1JQyT3\n9bhx4wCkpiES4rlzjXEwMXva+L3RhW2sz8wURBel2Bt5IIi1ouFwGBMnTkzbVngixPapPp+PLXLq\nES5alG63my3jYDCI6upqLoW7+OKL0dzczPxSXFycdst4wYIFAKDz2FANKcUqKRNUzBIPh8O8f3Yk\nEsH06dPTRqPophYtY6MrVOzKZrRyaS6KPFRYWIi//e1vfK6hyv3+kUHbudLOSjR+L774IgDgkUce\nQUNDAwAtlEc9FYC+cIvI56FQiL2L0WgUO3bswMMPPwxA29LV2GHqK1/5CgDg8ccfT5p2Y+kbtSeu\nrq7GT3/6UwDACy+8oDvm3nvvxfz585mmZOLrFouFwzuJoq2tjef5GWecgeLiYl6rWlpa4HK52J3s\n8Xh05XXf+c53uB/58ePH4ff78e///u/8/VD9COi8Rm9EohhSGCuKcgqAdQAqAKgA1qqq+rCiKKsB\nLAdANULfV1X1laHORw/tww8/xMqVKzmJxuPxoLOzk334xgQLsSEClQCR4LbZbLr2di0tLfjud7+L\n1tZWKIqCq666CkuWLMGTTz6JTZs2obS0FH6/H9dffz2effbZRMZpoLHRMWgoFOrnshVrz0RBF0+Q\nHz16FOvXr+cxoPh2uiHGVGjhFek2Kg0iXd3d3Rnb9rG0tJR54vjx4xzPcTgc6O7u5u8ikQjy8/P5\nfSAQwIwZM7gmtLOzEz6fDxs2bIDX682IS5O2gcvPz2fhajKZ0N7ezu8XLFiATZs2sbuVkoUI7e3t\neOqpp9JGoyiMKeEK0JQZCh95vV5dvJUEryhgFUVhwdHd3Y133nmHj3/66acxb948PPnkk0n37v1H\ngKqqyM/PH3DBvvvuu3H33XfrPiOBkZ+f36+JRSgUGtAt+vDDD+OGG27A/fffj3Xr1vFmKdT7eTC4\n3W5Oluzu7kZHRwevS8FgEIFAgHN4JkyYwE07tm7dimPHjvFe0bfddhv+8pe/9LungSCuNS0tLbjy\nyisTOk4E5SdccMEFOHLkCMuJiooKKIrC92G323XGUnt7uy45srW1Vac8xFuzic/9fj+HvcScEAAJ\ntwpOxE0dAbBCVdWpAC4AcKuiKFNPfPegqqozT/wNKYgzBbPZjJUrV+LJJ5/EI488gpdeeokf0OLF\ni/H73/8eP/vZzzjLbrTAbDbjsssuw0033cSfjYZesoNBURQWNLkEk8mEq6++Gvfcc09aGsCkAxaL\nBTfffHO2yUgKZrMZZ511Flc0rFu3jmP3pExJpAePPvoo79G8fPlytpppd6pcwHXXXZdtEjKGIS1j\nVVWbATSfeO1VFOXvAKqHe+HNmzdj8+bNuPTSSwFoFnNtbS1rF6IrjDI0CceOHYOqquxKCwaD6Onp\n0bl43W43Z9tWVlbi448/htfrxd69e7Fs2bK0WXPibkaixUDuuXhuPfq+rKwM1dXDHtqkEQgEWHuk\nEixj+QQhHA7rSrbKysq4rWS6UVpayuPZ1tbGvGKxWNDc3MyWMGnxxiQ04oeOjg643W6YTCb09vai\nurqam9OnC5s2bQIAXHLJJfxZLBbTZYATfWR5iok7gOZOT9eGHGJ5EqBPQqHNDADt+ZeUlDBNxrAG\n8Twdf+qpp2LatGl49dVXAWjVCx0dHXE3IDkZcOONN2LRokXsQRNDPgOBnnmyz762tpZ3s4tEInA4\nHHjrrbcSOtZut7N1S6VeFF5pb29HLBbjKpTnnnsOu3fvBqB1mJs1axZb1W+99RZWrFihKzNNtDQv\nHA5z4l8yIO9rQ0MDampqmD97enrg9Xp1u1zRumcMv7jdbixdupTPOZCLWuR9soTFNrvJIKmYsaIo\ndQDOArADwEUA/lVRlBsAvAvNeu7n71MU5SYANxk/J2zbtg1AX5tMyp4rLS1lV05NTQ0OHjzYb8vC\nZPDee+8l/NuhaCYYrdampibOGqTSGnqAVqtV994Y56bPhrNAJUq3ETt37mS6i4qKdFmp1PrQeK+U\nORiNRlOaMKnQ7Ha7uXRCjCU5HA6EQiEey7KyMhw/fpzjcmVlZSgtLWULnrLFRVd8OukG+mJ0a9eu\n5Qns8XjittOjvsXUZ5iqCAoKCjj2lgoGo1msgRfbWQJaT14qOTx27JiuZAbQl8ZRZjV939XVxTE8\nQIsZ3nXXXfjwww8Tih+mytPZxkB0d3Z2ora2loViYWFhvzirCDHGPlDvejEuLLqx33vvPcyePRvv\nvvsunn76abzwwgvsIUyE5tWrV+u+pw52NTU1KCkpQU1NDR3H3qVZs2YhPz+f48nPP/+8rnQ0mRr5\nSCSCTz75ZMjfGekmvlIUBfPnz8ePfvQjAMC5557brzXuQHjzzTdZNg0Gcf5S+RbF+JP1aiYsjBVF\ncQPYAOAOVVW7FUV5DMAaaHHkNQD+H4BlxuNUVV0LYO2JcwxJHblVRCQT9B8JJEszoaioiAUAFayL\nE8lYVylanbQN4IQJE1gDNpaNpItun8+HdevWAdAappSWlvJ9kFZNIE2eXI3btm1LundsqjRPmjSJ\nrysmXphMJt0Witu3b0dDQwML561bt+oWtaKiIvT29uLzzz9HOBxOaNINh24R06dP5/p4QL84lZeX\nA+grP3E6nbBYLCyMr7jiCq69TwWD0Sxu3WcymXTNZ8jSGAnce++9yM/PxzXXXIPKysohz53qOGcb\ng9F9+PBh9jTk5+ezUAO0hitiDbWowCcCcb7W19fD6XRi2bJlWLVqFRYtWjSoMB5qrKm8J5Eyn5FA\nV1cX7rrrLl0SVTwMRveWLVuwZcsWfj958mRuDjVjxgz2RJJyT95W2heb5sRAz0Ccvw888AAAsAKR\n7P7LCdnRiqJYoQni51RV3QgAqqq2qqoaVVU1BuBxAOcldWWJuIhEIty/+2TMNs0kYrEYXnvttYxs\ndCGhgepsS0pKsrLb1z86RGts/PjxADTlzrgjWK7gZOKRRLKpFQBPAPi7qqq/ED4feyKeDABXA8is\n+ToKYMym/uCDD7B3714AmjtKtIRNJhN6enp02Xtil6hQKISioiKsXbtWt/l8pu6DrMrNmzcD6GtP\nWllZqXPttLS06DaLzyRuueUW3W5B//Vf/wVAy+Y8dOgQWxgHDx7UuUYBzdVKyGYW70cffcSL4uzZ\nszF16lTMnTsXANh1+eijjwLQLOX169fzM0kn2tvbOdzQ2NjIGzEAie/Qkwiee+45jB8/Hh0dHXj/\n/feHda5chaIoXELT3t7OJZpAcm7ceBDXjGPHjsHv96OlpQUlJSUZ3Z1spPBv//ZvI3q+ffv2MZ8P\nFh4gDMXv4vevvfaa7rtku54pCey+MRvAmwD2AKCn+X0A1wOYCc1NfRDAzYJwHuhcxwH0AvAkRWXy\ncAM4DYDYl+wogBIATmhKiA/AIQBhALWqqsbtjZhBmoHk6K4aiGYAUBTFC2DogMvwIcd6dI71UDTL\nuTg4/tH5Q451elGKvrEbcJxFDCmMRxqKoryrqmpWc+uTpWE00JwsHblIcyq/TxfkWGcGuUhzsnTk\nIs2p/D5dOBnGGpDtMCUkJCQkJLIOKYwlJCQkJCSyjGwI47VZuKYRydIwGmgGkqMjF2lO5ffpghzr\nzCAXaQYkf2QSJ8NYZz5mLCEhISEhIaGHdFNLSEhISEhkGRkTxoqizFcU5RNFUT5VFCWxLTxG5rqn\nKIqyTVGUvYqi/E1RlNtPfL5aUZSjiqJ8eOLvS6OF7lykebh05yLN2aI7F2nOVbpzkebh0p2LNGeL\n7uHSrIOqqmn/A2AGcADAeAA2AH8FMDVD1x4L4OwTr/MB7AMwFcBqACtHI925SPNw6M5FmiV/nBx0\n5yLNw6E7F2nOVf4w/mXKMj4PwKeqqn6mqmoIwHoAX83EhVVVbVZV9f0Tr70Aktl1Kit05yLNwLDo\nzkWaAckfSSEX6c5FmgE5F5Eb/KFDpoRxNYAjwvtGjMA2jMlC0e86BWi7Tu1WFOVJRVGK4xySdbpz\nkWYgabpzkWZgFNCdizQDuUl3LtIMyLmYKaRAsw4nTQKXYth1CsBjACZAa+nZDG3XqVGFXKQZyE26\nJc2ZQy7SnYs0A7lJ98lKc6aE8VEApwjva058lhEoqe86lTW6c5FmIGW6c5FmQPJH0shFunORZkDO\nRYx+/tBjuAHsRP6gNfr+DMA49AXXz8jQtRUA6wA8ZPh8rPD6TgDrRwvduUjzcOjORZolf5wcdOci\nzcOhOxdpzlX+6HeuTAzyCYK+BC3T7ACAezJ43dnQdpbaDeDDE39fAvBbaDtR7QbwB3Hwsk13LtI8\nXLpzkWbJH//4dOcizcOlOxdpzlX+EP9kBy4JCQkJCYks46RJ4JKQkJCQkBitkMJYQkJCQkIiy5DC\nWEJCQkJCIsuQwlhCQkJCQiLLkMJYQkJCQkIiy5DCWEJCQkJCIsuQwlhCQkJCQiLLkMJYQkJCQkIi\ny/j/mB1+6NFd2+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0 2 7 2 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(10):    \n",
    "    plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(trainX[i,:].reshape([28,28]), cmap='gray')\n",
    "plt.show()\n",
    "print(trainlabelsY[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Building a Neural Network without Batch Normalization\n",
    "\n",
    "#Initialize Sequential model\n",
    "model1 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd optimizer\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87559,
     "status": "ok",
     "timestamp": 1579416210862,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "O59C_-IgOIVB",
    "outputId": "cf5ec337-b3c3-4bec-8dfb-5b7bd53056c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 2055.6271 - acc: 0.7393 - val_loss: 2854.6495 - val_acc: 0.6892\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1625.1838 - acc: 0.7768 - val_loss: 1316.2704 - val_acc: 0.7890\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1555.1421 - acc: 0.7862 - val_loss: 1648.6645 - val_acc: 0.7349\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1566.9990 - acc: 0.7887 - val_loss: 1940.2423 - val_acc: 0.7300\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1525.6621 - acc: 0.7912 - val_loss: 1657.7487 - val_acc: 0.7841\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1481.9317 - acc: 0.7954 - val_loss: 1926.4529 - val_acc: 0.7794\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1478.6845 - acc: 0.7970 - val_loss: 1379.8758 - val_acc: 0.7856\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1477.6822 - acc: 0.7957 - val_loss: 1438.3595 - val_acc: 0.7491\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1406.6971 - acc: 0.8003 - val_loss: 1292.2812 - val_acc: 0.7854\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1419.5032 - acc: 0.8002 - val_loss: 2389.3822 - val_acc: 0.7512\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1439.8028 - acc: 0.8006 - val_loss: 1265.6117 - val_acc: 0.7822\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1437.6199 - acc: 0.8009 - val_loss: 1217.3219 - val_acc: 0.7967\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1450.4644 - acc: 0.7993 - val_loss: 1094.7470 - val_acc: 0.8224\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1374.9429 - acc: 0.8033 - val_loss: 1507.0473 - val_acc: 0.7668\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1425.5605 - acc: 0.8027 - val_loss: 1060.0446 - val_acc: 0.7882\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1421.5403 - acc: 0.8035 - val_loss: 2498.1549 - val_acc: 0.7564\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1346.8525 - acc: 0.8065 - val_loss: 1665.0410 - val_acc: 0.8078\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 1406.1626 - acc: 0.8034 - val_loss: 1378.9656 - val_acc: 0.7882\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1373.0224 - acc: 0.8049 - val_loss: 2518.4160 - val_acc: 0.7579\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1404.5057 - acc: 0.8049 - val_loss: 996.5396 - val_acc: 0.8277\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1364.0411 - acc: 0.8079 - val_loss: 1601.5789 - val_acc: 0.7928\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1398.5660 - acc: 0.8050 - val_loss: 1629.2789 - val_acc: 0.7982\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1383.9425 - acc: 0.8053 - val_loss: 1433.2905 - val_acc: 0.8023\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1381.4392 - acc: 0.8055 - val_loss: 1601.6862 - val_acc: 0.7932\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1410.9555 - acc: 0.8068 - val_loss: 3258.7989 - val_acc: 0.7247\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1365.2501 - acc: 0.8073 - val_loss: 1071.8577 - val_acc: 0.8119\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1357.2365 - acc: 0.8090 - val_loss: 1301.0610 - val_acc: 0.7884\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 1370.8157 - acc: 0.8084 - val_loss: 1162.5008 - val_acc: 0.8024\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1396.5650 - acc: 0.8077 - val_loss: 1189.3139 - val_acc: 0.8124\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1364.3142 - acc: 0.8084 - val_loss: 1098.8853 - val_acc: 0.8119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf91e0518>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model1.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Building a Neural Network with Batch Normalization layer\n",
    "\n",
    "#Initialize Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd optimizer\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 202110,
     "status": "ok",
     "timestamp": 1579416325442,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "JNLR8tcBOIVP",
    "outputId": "8fc331e3-dfb7-43ef-f0d1-14b8031ae9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.5995 - acc: 0.7923 - val_loss: 0.5166 - val_acc: 0.8221\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4891 - acc: 0.8311 - val_loss: 0.4834 - val_acc: 0.8311\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4689 - acc: 0.8372 - val_loss: 0.4754 - val_acc: 0.8325\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4561 - acc: 0.8427 - val_loss: 0.4739 - val_acc: 0.8357\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4490 - acc: 0.8433 - val_loss: 0.4643 - val_acc: 0.8381\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4465 - acc: 0.8453 - val_loss: 0.4725 - val_acc: 0.8337\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4397 - acc: 0.8474 - val_loss: 0.4614 - val_acc: 0.8384\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4369 - acc: 0.8468 - val_loss: 0.4666 - val_acc: 0.8375\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4302 - acc: 0.8492 - val_loss: 0.4630 - val_acc: 0.8402\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4290 - acc: 0.8503 - val_loss: 0.4687 - val_acc: 0.8423\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4303 - acc: 0.8502 - val_loss: 0.4662 - val_acc: 0.8418\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4250 - acc: 0.8517 - val_loss: 0.4683 - val_acc: 0.8422\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4226 - acc: 0.8523 - val_loss: 0.4769 - val_acc: 0.8399\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4252 - acc: 0.8509 - val_loss: 0.4600 - val_acc: 0.8422\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4230 - acc: 0.8525 - val_loss: 0.4623 - val_acc: 0.8398\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4218 - acc: 0.8528 - val_loss: 0.4634 - val_acc: 0.8433\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4187 - acc: 0.8526 - val_loss: 0.4615 - val_acc: 0.8426\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4177 - acc: 0.8548 - val_loss: 0.4631 - val_acc: 0.8395\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4153 - acc: 0.8539 - val_loss: 0.4581 - val_acc: 0.8418\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4172 - acc: 0.8532 - val_loss: 0.4718 - val_acc: 0.8412\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4149 - acc: 0.8553 - val_loss: 0.4577 - val_acc: 0.8420\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4176 - acc: 0.8545 - val_loss: 0.4667 - val_acc: 0.8376\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4160 - acc: 0.8542 - val_loss: 0.4662 - val_acc: 0.8395\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4149 - acc: 0.8540 - val_loss: 0.4772 - val_acc: 0.8399\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4153 - acc: 0.8541 - val_loss: 0.4668 - val_acc: 0.8393\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4149 - acc: 0.8531 - val_loss: 0.4703 - val_acc: 0.8397\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4131 - acc: 0.8555 - val_loss: 0.4644 - val_acc: 0.8371\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4115 - acc: 0.8564 - val_loss: 0.4747 - val_acc: 0.8389\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4111 - acc: 0.8553 - val_loss: 0.4741 - val_acc: 0.8413\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4115 - acc: 0.8546 - val_loss: 0.4796 - val_acc: 0.8371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf8dd6be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model2.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "#Build a Neural Network with learning rate set to 0.001 in sgd optimizer\n",
    "\n",
    "#Initialize Sequential model\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model3.add(tf.keras.layers.Reshape((784,), input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Customize the learning rate to 0.001 in sgd optimizer\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd_optimizer with lr=0.001\n",
    "model3.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bv63ZySUwUdg"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 314457,
     "status": "ok",
     "timestamp": 1579416437819,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "pJUqA5T4OIVc",
    "outputId": "375ee604-28f8-4519-fa19-46c6911c6413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.9395 - acc: 0.6810 - val_loss: 0.7233 - val_acc: 0.7576\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.6527 - acc: 0.7747 - val_loss: 0.6375 - val_acc: 0.7879\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5959 - acc: 0.7952 - val_loss: 0.5828 - val_acc: 0.8009\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5628 - acc: 0.8051 - val_loss: 0.5608 - val_acc: 0.8072\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5430 - acc: 0.8138 - val_loss: 0.5522 - val_acc: 0.8139\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5282 - acc: 0.8179 - val_loss: 0.5417 - val_acc: 0.8169\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5163 - acc: 0.8221 - val_loss: 0.5266 - val_acc: 0.8204\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5080 - acc: 0.8245 - val_loss: 0.5157 - val_acc: 0.8215\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5022 - acc: 0.8261 - val_loss: 0.5164 - val_acc: 0.8230\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4963 - acc: 0.8280 - val_loss: 0.5100 - val_acc: 0.8247\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4912 - acc: 0.8316 - val_loss: 0.5154 - val_acc: 0.8270\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4863 - acc: 0.8343 - val_loss: 0.4923 - val_acc: 0.8286\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4794 - acc: 0.8353 - val_loss: 0.4949 - val_acc: 0.8294\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4807 - acc: 0.8355 - val_loss: 0.4915 - val_acc: 0.8293\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4731 - acc: 0.8371 - val_loss: 0.4896 - val_acc: 0.8310\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4711 - acc: 0.8376 - val_loss: 0.4912 - val_acc: 0.8329\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4681 - acc: 0.8389 - val_loss: 0.4862 - val_acc: 0.8320\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4653 - acc: 0.8406 - val_loss: 0.4868 - val_acc: 0.8334\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4651 - acc: 0.8408 - val_loss: 0.4808 - val_acc: 0.8352\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4619 - acc: 0.8411 - val_loss: 0.4805 - val_acc: 0.8354\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4605 - acc: 0.8432 - val_loss: 0.4764 - val_acc: 0.8366\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4585 - acc: 0.8406 - val_loss: 0.4811 - val_acc: 0.8363\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4573 - acc: 0.8424 - val_loss: 0.4751 - val_acc: 0.8364\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4571 - acc: 0.8434 - val_loss: 0.4830 - val_acc: 0.8353\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4538 - acc: 0.8429 - val_loss: 0.4786 - val_acc: 0.8362\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4517 - acc: 0.8444 - val_loss: 0.4757 - val_acc: 0.8362\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4524 - acc: 0.8446 - val_loss: 0.4759 - val_acc: 0.8368\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4514 - acc: 0.8442 - val_loss: 0.4772 - val_acc: 0.8384\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4492 - acc: 0.8452 - val_loss: 0.4736 - val_acc: 0.8383\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4470 - acc: 0.8457 - val_loss: 0.4677 - val_acc: 0.8375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf916fcf8>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model3.fit(trainX, trainY, \n",
    "           validation_data=(testX,testY),\n",
    "           epochs=30, \n",
    "           batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and sigmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Build a Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer\n",
    "#Use cross entropy loss function and sigmoid as activation in the hidden layers\n",
    "#Use softmax as activation function in the output layer\n",
    "#Use sgd optimizer with learning rate 0.03\n",
    "\n",
    "#Initialize Sequential model\n",
    "model4 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model4.add(tf.keras.layers.Reshape(target_shape=(784,), input_shape=(28,28)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer()\n",
    "model4.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 1 with 100 neurons and activation function as sigmoid \n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 2 with 100 neurons and activation function as sigmoid\n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 3 with 10 neurons and activation function as sigmoid\n",
    "model4.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs as we have 10 classes after 3 Hidden layers by applying activation function as softmax \n",
    "model4.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQ7oIymROIVp"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "#Use cross entropy loss function\n",
    "#Use sgd optimizer with learning rate 0.03\n",
    "\n",
    "sgd_optimizer2 = tf.keras.optimizers.SGD(learning_rate=0.03)\n",
    "model4.compile(optimizer=sgd_optimizer2, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BS7L5Z2c7U-J"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474795,
     "status": "ok",
     "timestamp": 1579416598191,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "BiP7IL52OIVw",
    "outputId": "c71109e8-d48d-449c-9010-745cb197506c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 1.8242 - acc: 0.4076 - val_loss: 1.3360 - val_acc: 0.6290\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1.0853 - acc: 0.6483 - val_loss: 0.8786 - val_acc: 0.7220\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.7865 - acc: 0.7376 - val_loss: 0.6891 - val_acc: 0.7689\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.6628 - acc: 0.7712 - val_loss: 0.6096 - val_acc: 0.7890\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.5975 - acc: 0.7934 - val_loss: 0.5580 - val_acc: 0.8082\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.5479 - acc: 0.8141 - val_loss: 0.5222 - val_acc: 0.8223\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.5104 - acc: 0.8270 - val_loss: 0.4951 - val_acc: 0.8309\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.4849 - acc: 0.8372 - val_loss: 0.4738 - val_acc: 0.8377\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4647 - acc: 0.8422 - val_loss: 0.4573 - val_acc: 0.8404\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.4428 - acc: 0.8499 - val_loss: 0.4453 - val_acc: 0.8478\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.4279 - acc: 0.8543 - val_loss: 0.4337 - val_acc: 0.8491\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4115 - acc: 0.8590 - val_loss: 0.4164 - val_acc: 0.8557\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3993 - acc: 0.8631 - val_loss: 0.4043 - val_acc: 0.8583\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3870 - acc: 0.8668 - val_loss: 0.4035 - val_acc: 0.8593\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3766 - acc: 0.8706 - val_loss: 0.3961 - val_acc: 0.8623\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3654 - acc: 0.8740 - val_loss: 0.3871 - val_acc: 0.8656\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3544 - acc: 0.8773 - val_loss: 0.3888 - val_acc: 0.8643\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.3466 - acc: 0.8810 - val_loss: 0.3827 - val_acc: 0.8665\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.3388 - acc: 0.8821 - val_loss: 0.3749 - val_acc: 0.8693\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3301 - acc: 0.8854 - val_loss: 0.3704 - val_acc: 0.8719\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3236 - acc: 0.8869 - val_loss: 0.3662 - val_acc: 0.8728\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3161 - acc: 0.8899 - val_loss: 0.3678 - val_acc: 0.8702\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3087 - acc: 0.8917 - val_loss: 0.3628 - val_acc: 0.8738\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3053 - acc: 0.8920 - val_loss: 0.3580 - val_acc: 0.8749\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2992 - acc: 0.8949 - val_loss: 0.3581 - val_acc: 0.8745\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2929 - acc: 0.8982 - val_loss: 0.3554 - val_acc: 0.8768\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2876 - acc: 0.8992 - val_loss: 0.3589 - val_acc: 0.8742\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2837 - acc: 0.9005 - val_loss: 0.3572 - val_acc: 0.8768\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2777 - acc: 0.9029 - val_loss: 0.3557 - val_acc: 0.8764\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2738 - acc: 0.9026 - val_loss: 0.3522 - val_acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf8caf898>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model4.fit(trainX, trainY,\n",
    "           validation_data=(testX, testY),\n",
    "           epochs=30,\n",
    "           batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474752,
     "status": "ok",
     "timestamp": 1579416598198,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "h4ojW6-oOIV2",
    "outputId": "cfbdfb30-6fcb-45a6-934a-7c4b3f824613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_7 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 92,856\n",
      "Trainable params: 91,288\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjmDJbvomwGw"
   },
   "outputs": [],
   "source": [
    "all_weights= model4.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1459,
     "status": "ok",
     "timestamp": 1579417573338,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "bIkbMEN5OIV7",
    "outputId": "1f58a973-57df-4d5a-8500-8b75afe46a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.expand_dims(testX[0], axis=0)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1579417818761,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "grWwAthTn5Fu",
    "outputId": "94cdcc25-0a0c-4560-cb49-7c5e824e3c93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.23548263e-05, 4.15228969e-05, 1.02841376e-07, 1.27672974e-03,\n",
       "        6.14521059e-06, 2.28528469e-03, 1.02528793e-05, 1.22581720e-02,\n",
       "        9.91950859e-04, 9.83087480e-01]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model4.predict(input_data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1579417849818,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "MnZuATpOn8L0",
    "outputId": "02efc77e-2d16-4ef7-e744-23c05f1eb888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1151,
     "status": "ok",
     "timestamp": 1579417989406,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "qkWWqeOTo8cB",
    "outputId": "ec50768e-e849-4a6f-9133-5c21bb62932b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.23548263e-05, 4.15228969e-05, 1.02841376e-07, 1.27672974e-03,\n",
       "       6.14521059e-06, 2.28528469e-03, 1.02528793e-05, 1.22581720e-02,\n",
       "       9.91950859e-04, 9.83087480e-01], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1579418027579,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "kwQsVa9apew6",
    "outputId": "1c5b9251-5cbf-4374-ef64-60a1db32fcf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1579418101918,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "oKt8uPMLpoHk",
    "outputId": "75cfcaee-e1a7-47d0-fbbe-2c67529ff433"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkARhB5Ig7EAShB1IgrADSfwvFVP+6jE8J4kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the image\n",
    "plt.imshow(testX[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1579418142889,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "PldEwsoxp2uA",
    "outputId": "fed93bea-abd4-4284-a3be-bf53a9f7e003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(testY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBEQaDWHqEOg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R6_ExternalLab_AIML-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
